(1) Set up para el funcionamiento

(1.1) Necesitamos conda para instalar el video features (2+1)
(1.2) Insatalamos video features

(2) Pasos para los datos

(2.1) Recordar los datos a un subdataset de los unicos links que tienen subset_10. 
      Eso, para filtrar a solo los videos que vamos a usar.

(3) Análisis de los datos

(3.1) Para realizar el análisis de datos primero debemos obtener los resultados de "video_features".

--------
Estructura
- Notas
- video_features (es un link a otro github, cuando se hace clone de mi repo aparece como carpeta vacia
                  por lo que cada uno lo tiene que clonear independientemente 
                  https://github.com/v-iashin/video_features.git)
                  - I0luMKjIZyg de val es un video nulo. 
- recortar_datos (aquí eliminamos videos queno vayamos a usar para ocupar menos espacio en vano)
- read_process (aquí obtendremos los features)
- data_normalizer (compactaremos los datos de los csv para hacer un txt de puros paths que pueda ponerse
                  como parametro en --parece que video_paths no acepta solo una llena de videos--) 

--------
Choices justify:
- Video features porque ofrece varios modelos, en especial R(2+1)D el que usaremos por tener un enfoque más útil para nuestro proyecto. 
  así mismo no usamos semegantes como CLIP o S3D porque CLIP era muy pesado y entre S3D y R(2+1)D, preferimos R(2+1)D por su modelo 
  r2plus1d_34_32_ig65m_ft_kinetics que tiene un 79.10 de accuracy a comparación del de por default en R(2+1)D. 
- umap